{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3879",
   "metadata": {},
   "source": [
    "# Подготовка модели распознавания рукописных букв и цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea756f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize, Lambda\n",
    "from torchvision.transforms.functional import rotate, hflip\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = EMNIST('data/', 'balanced', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c115ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0',\n",
       " 1: '1',\n",
       " 2: '2',\n",
       " 3: '3',\n",
       " 4: '4',\n",
       " 5: '5',\n",
       " 6: '6',\n",
       " 7: '7',\n",
       " 8: '8',\n",
       " 9: '9',\n",
       " 10: 'A',\n",
       " 11: 'B',\n",
       " 12: 'C',\n",
       " 13: 'D',\n",
       " 14: 'E',\n",
       " 15: 'F',\n",
       " 16: 'G',\n",
       " 17: 'H',\n",
       " 18: 'I',\n",
       " 19: 'J',\n",
       " 20: 'K',\n",
       " 21: 'L',\n",
       " 22: 'M',\n",
       " 23: 'N',\n",
       " 24: 'O',\n",
       " 25: 'P',\n",
       " 26: 'Q',\n",
       " 27: 'R',\n",
       " 28: 'S',\n",
       " 29: 'T',\n",
       " 30: 'U',\n",
       " 31: 'V',\n",
       " 32: 'W',\n",
       " 33: 'X',\n",
       " 34: 'Y',\n",
       " 35: 'Z',\n",
       " 36: 'a',\n",
       " 37: 'b',\n",
       " 38: 'd',\n",
       " 39: 'e',\n",
       " 40: 'f',\n",
       " 41: 'g',\n",
       " 42: 'h',\n",
       " 43: 'n',\n",
       " 44: 'q',\n",
       " 45: 'r',\n",
       " 46: 't'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {}\n",
    "\n",
    "with open('data/EMNIST/raw/emnist-balanced-mapping.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        label, code = line.strip().split()\n",
    "        mapping[int(label)] = chr(int(code))\n",
    "        \n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9f9be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 10, figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    axs[i].imshow(dataset[i][0], cmap='gray')\n",
    "    axs[i].set_title(mapping[dataset[i][1]])\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d90266",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Lambda(lambda x: rotate(x, -90)),\n",
    "    Lambda(lambda x: hflip(x)),\n",
    "    ToTensor(),\n",
    "    Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = EMNIST('data/', 'balanced', train=True, download=False, transform=transform)\n",
    "val_dataset = EMNIST('data/', 'balanced', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa247ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 2400, '1': 2400, '2': 2400, '3': 2400, '4': 2400, '5': 2400, '6': 2400, '7': 2400, '8': 2400, '9': 2400, 'A': 2400, 'B': 2400, 'C': 2400, 'D': 2400, 'E': 2400, 'F': 2400, 'G': 2400, 'H': 2400, 'I': 2400, 'J': 2400, 'K': 2400, 'L': 2400, 'M': 2400, 'N': 2400, 'O': 2400, 'P': 2400, 'Q': 2400, 'R': 2400, 'S': 2400, 'T': 2400, 'U': 2400, 'V': 2400, 'W': 2400, 'X': 2400, 'Y': 2400, 'Z': 2400, 'a': 2400, 'b': 2400, 'd': 2400, 'e': 2400, 'f': 2400, 'g': 2400, 'h': 2400, 'n': 2400, 'q': 2400, 'r': 2400, 't': 2400}\n",
      "{'0': 400, '1': 400, '2': 400, '3': 400, '4': 400, '5': 400, '6': 400, '7': 400, '8': 400, '9': 400, 'A': 400, 'B': 400, 'C': 400, 'D': 400, 'E': 400, 'F': 400, 'G': 400, 'H': 400, 'I': 400, 'J': 400, 'K': 400, 'L': 400, 'M': 400, 'N': 400, 'O': 400, 'P': 400, 'Q': 400, 'R': 400, 'S': 400, 'T': 400, 'U': 400, 'V': 400, 'W': 400, 'X': 400, 'Y': 400, 'Z': 400, 'a': 400, 'b': 400, 'd': 400, 'e': 400, 'f': 400, 'g': 400, 'h': 400, 'n': 400, 'q': 400, 'r': 400, 't': 400}\n"
     ]
    }
   ],
   "source": [
    "train_counts = {i: 0 for i in mapping.values()}\n",
    "for _, target in train_dataset:\n",
    "    symbol = mapping[int(target)]\n",
    "    train_counts[symbol] += 1\n",
    "\n",
    "val_counts = {i: 0 for i in mapping.values()}\n",
    "for _, target in val_dataset:\n",
    "    symbol = mapping[int(target)]\n",
    "    val_counts[symbol] += 1\n",
    "    \n",
    "print(train_counts)\n",
    "print(val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350da865",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2eb6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        print(f'Epoch: {epoch}')\n",
    "        current_lr = get_current_lr(optimizer)\n",
    "        print(f'Current Learning Rate: {current_lr}')\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                print(f'Iter: {step} \\tLoss: {loss.item()}')\n",
    "\n",
    "        print(f'Mean Train Loss: {loss_sum / (step + 1):.6f}', end='\\n\\n')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            val_loss = validate(model, val_loader, loss_f)\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "def validate(model, val_loader, loss_f):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}')\n",
    "    model.train()\n",
    "    return loss_sum / (step + 1)\n",
    "\n",
    "def get_current_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b0b4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      [1, 47]                   --\n",
       "├─Sequential: 1-1                        [1, 128, 14, 14]          --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 28, 28]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-4                    [1, 32, 14, 14]           --\n",
       "│    └─Dropout: 2-5                      [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-6                       [1, 64, 14, 14]           51,264\n",
       "│    └─BatchNorm2d: 2-7                  [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-8                         [1, 64, 14, 14]           --\n",
       "│    └─Dropout: 2-9                      [1, 64, 14, 14]           --\n",
       "│    └─Conv2d: 2-10                      [1, 128, 14, 14]          401,536\n",
       "│    └─BatchNorm2d: 2-11                 [1, 128, 14, 14]          256\n",
       "│    └─ReLU: 2-12                        [1, 128, 14, 14]          --\n",
       "│    └─Dropout: 2-13                     [1, 128, 14, 14]          --\n",
       "├─Sequential: 1-2                        [1, 64, 14, 14]           --\n",
       "│    └─ConvTranspose2d: 2-14             [1, 64, 14, 14]           73,792\n",
       "│    └─BatchNorm2d: 2-15                 [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-16                        [1, 64, 14, 14]           --\n",
       "│    └─Dropout: 2-17                     [1, 64, 14, 14]           --\n",
       "├─Sequential: 1-3                        [1, 47]                   --\n",
       "│    └─Flatten: 2-18                     [1, 12544]                --\n",
       "│    └─Linear: 2-19                      [1, 6272]                 78,682,240\n",
       "│    └─ReLU: 2-20                        [1, 6272]                 --\n",
       "│    └─Dropout: 2-21                     [1, 6272]                 --\n",
       "│    └─Linear: 2-22                      [1, 3136]                 19,672,128\n",
       "│    └─ReLU: 2-23                        [1, 3136]                 --\n",
       "│    └─Dropout: 2-24                     [1, 3136]                 --\n",
       "│    └─Linear: 2-25                      [1, 47]                   147,439\n",
       "==========================================================================================\n",
       "Total params: 99,029,295\n",
       "Trainable params: 99,029,295\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 201.97\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.28\n",
       "Params size (MB): 396.12\n",
       "Estimated Total Size (MB): 397.40\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=12544, out_features=6272),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(in_features=6272, out_features=3136),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(in_features=3136, out_features=n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "net = CNN(47)\n",
    "summary(net, input_size=(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b4f0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 3.8632583618164062\n",
      "Iter: 10 \tLoss: 4.171310901641846\n",
      "Iter: 20 \tLoss: 2.478304862976074\n",
      "Iter: 30 \tLoss: 1.2813737392425537\n",
      "Iter: 40 \tLoss: 0.8724743723869324\n",
      "Iter: 50 \tLoss: 0.7259830236434937\n",
      "Iter: 60 \tLoss: 0.6013151407241821\n",
      "Iter: 70 \tLoss: 0.5402480363845825\n",
      "Iter: 80 \tLoss: 0.5417232513427734\n",
      "Iter: 90 \tLoss: 0.5266383290290833\n",
      "Iter: 100 \tLoss: 0.517001748085022\n",
      "Iter: 110 \tLoss: 0.4685957431793213\n",
      "Mean Train Loss: 1.251415\n",
      "\n",
      "Val Loss: 0.423857 \tAccuracy: 0.8523936170212766\n",
      "Epoch: 1\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.4282047152519226\n",
      "Iter: 10 \tLoss: 0.42521724104881287\n",
      "Iter: 20 \tLoss: 0.4193362295627594\n",
      "Iter: 30 \tLoss: 0.45203927159309387\n",
      "Iter: 40 \tLoss: 0.3992222249507904\n",
      "Iter: 50 \tLoss: 0.36989325284957886\n",
      "Iter: 60 \tLoss: 0.4072627127170563\n",
      "Iter: 70 \tLoss: 0.4120623767375946\n",
      "Iter: 80 \tLoss: 0.4268612861633301\n",
      "Iter: 90 \tLoss: 0.3653380870819092\n",
      "Iter: 100 \tLoss: 0.37032511830329895\n",
      "Iter: 110 \tLoss: 0.36708396673202515\n",
      "Mean Train Loss: 0.407830\n",
      "\n",
      "Epoch: 2\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.33195391297340393\n",
      "Iter: 10 \tLoss: 0.37720924615859985\n",
      "Iter: 20 \tLoss: 0.3238016366958618\n",
      "Iter: 30 \tLoss: 0.33506709337234497\n",
      "Iter: 40 \tLoss: 0.3226982653141022\n",
      "Iter: 50 \tLoss: 0.326731413602829\n",
      "Iter: 60 \tLoss: 0.3553965389728546\n",
      "Iter: 70 \tLoss: 0.33810192346572876\n",
      "Iter: 80 \tLoss: 0.3773810863494873\n",
      "Iter: 90 \tLoss: 0.3297951817512512\n",
      "Iter: 100 \tLoss: 0.3572661876678467\n",
      "Iter: 110 \tLoss: 0.37622663378715515\n",
      "Mean Train Loss: 0.349997\n",
      "\n",
      "Val Loss: 0.325439 \tAccuracy: 0.8834574468085107\n",
      "Epoch: 3\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.305464506149292\n",
      "Iter: 10 \tLoss: 0.29964640736579895\n",
      "Iter: 20 \tLoss: 0.3580295145511627\n",
      "Iter: 30 \tLoss: 0.38041040301322937\n",
      "Iter: 40 \tLoss: 0.3598617613315582\n",
      "Iter: 50 \tLoss: 0.2662758529186249\n",
      "Iter: 60 \tLoss: 0.30522581934928894\n",
      "Iter: 70 \tLoss: 0.315896600484848\n",
      "Iter: 80 \tLoss: 0.28439241647720337\n",
      "Iter: 90 \tLoss: 0.3195541799068451\n",
      "Iter: 100 \tLoss: 0.32884618639945984\n",
      "Iter: 110 \tLoss: 0.3268458843231201\n",
      "Mean Train Loss: 0.320927\n",
      "\n",
      "Epoch: 4\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.311142235994339\n",
      "Iter: 10 \tLoss: 0.24836476147174835\n",
      "Iter: 20 \tLoss: 0.29496869444847107\n",
      "Iter: 30 \tLoss: 0.2754797339439392\n",
      "Iter: 40 \tLoss: 0.2640668749809265\n",
      "Iter: 50 \tLoss: 0.26241618394851685\n",
      "Iter: 60 \tLoss: 0.3042167127132416\n",
      "Iter: 70 \tLoss: 0.2868817448616028\n",
      "Iter: 80 \tLoss: 0.33223652839660645\n",
      "Iter: 90 \tLoss: 0.2764512598514557\n",
      "Iter: 100 \tLoss: 0.2808520793914795\n",
      "Iter: 110 \tLoss: 0.2659427523612976\n",
      "Mean Train Loss: 0.297224\n",
      "\n",
      "Val Loss: 0.329235 \tAccuracy: 0.8812234042553192\n",
      "Epoch: 5\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.303648442029953\n",
      "Iter: 10 \tLoss: 0.24890565872192383\n",
      "Iter: 20 \tLoss: 0.2556641697883606\n",
      "Iter: 30 \tLoss: 0.26712724566459656\n",
      "Iter: 40 \tLoss: 0.307168185710907\n",
      "Iter: 50 \tLoss: 0.28620630502700806\n",
      "Iter: 60 \tLoss: 0.3023855984210968\n",
      "Iter: 70 \tLoss: 0.284974068403244\n",
      "Iter: 80 \tLoss: 0.27271410822868347\n",
      "Iter: 90 \tLoss: 0.29552993178367615\n",
      "Iter: 100 \tLoss: 0.291616290807724\n",
      "Iter: 110 \tLoss: 0.24156011641025543\n",
      "Mean Train Loss: 0.282180\n",
      "\n",
      "Epoch: 6\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.24079465866088867\n",
      "Iter: 10 \tLoss: 0.2519487738609314\n",
      "Iter: 20 \tLoss: 0.26593679189682007\n",
      "Iter: 30 \tLoss: 0.2897920310497284\n",
      "Iter: 40 \tLoss: 0.21467168629169464\n",
      "Iter: 50 \tLoss: 0.27655959129333496\n",
      "Iter: 60 \tLoss: 0.29279524087905884\n",
      "Iter: 70 \tLoss: 0.26598358154296875\n",
      "Iter: 80 \tLoss: 0.24806886911392212\n",
      "Iter: 90 \tLoss: 0.2961423695087433\n",
      "Iter: 100 \tLoss: 0.24500200152397156\n",
      "Iter: 110 \tLoss: 0.2717888355255127\n",
      "Mean Train Loss: 0.268506\n",
      "\n",
      "Val Loss: 0.302651 \tAccuracy: 0.8933510638297872\n",
      "Epoch: 7\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.2583421766757965\n",
      "Iter: 10 \tLoss: 0.28828510642051697\n",
      "Iter: 20 \tLoss: 0.26165705919265747\n",
      "Iter: 30 \tLoss: 0.23036766052246094\n",
      "Iter: 40 \tLoss: 0.2440013736486435\n",
      "Iter: 50 \tLoss: 0.2371128350496292\n",
      "Iter: 60 \tLoss: 0.24521851539611816\n",
      "Iter: 70 \tLoss: 0.2500475347042084\n",
      "Iter: 80 \tLoss: 0.2216768115758896\n",
      "Iter: 90 \tLoss: 0.2567329406738281\n",
      "Iter: 100 \tLoss: 0.24836960434913635\n",
      "Iter: 110 \tLoss: 0.2373795211315155\n",
      "Mean Train Loss: 0.254915\n",
      "\n",
      "Epoch: 8\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.22690074145793915\n",
      "Iter: 10 \tLoss: 0.2239256352186203\n",
      "Iter: 20 \tLoss: 0.23373015224933624\n",
      "Iter: 30 \tLoss: 0.2333081066608429\n",
      "Iter: 40 \tLoss: 0.2489541471004486\n",
      "Iter: 50 \tLoss: 0.2228555530309677\n",
      "Iter: 60 \tLoss: 0.2551666796207428\n",
      "Iter: 70 \tLoss: 0.23852582275867462\n",
      "Iter: 80 \tLoss: 0.2493356466293335\n",
      "Iter: 90 \tLoss: 0.26342323422431946\n",
      "Iter: 100 \tLoss: 0.26338884234428406\n",
      "Iter: 110 \tLoss: 0.2469959706068039\n",
      "Mean Train Loss: 0.245271\n",
      "\n",
      "Val Loss: 0.302961 \tAccuracy: 0.893031914893617\n",
      "Epoch: 9\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.23246978223323822\n",
      "Iter: 10 \tLoss: 0.23093420267105103\n",
      "Iter: 20 \tLoss: 0.26093828678131104\n",
      "Iter: 30 \tLoss: 0.2515382766723633\n",
      "Iter: 40 \tLoss: 0.193709596991539\n",
      "Iter: 50 \tLoss: 0.2502949833869934\n",
      "Iter: 60 \tLoss: 0.23542125523090363\n",
      "Iter: 70 \tLoss: 0.2673037350177765\n",
      "Iter: 80 \tLoss: 0.24024751782417297\n",
      "Iter: 90 \tLoss: 0.240857794880867\n",
      "Iter: 100 \tLoss: 0.25639933347702026\n",
      "Iter: 110 \tLoss: 0.24797864258289337\n",
      "Mean Train Loss: 0.233634\n",
      "\n",
      "Epoch: 10\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.22022706270217896\n",
      "Iter: 10 \tLoss: 0.2116841971874237\n",
      "Iter: 20 \tLoss: 0.24393337965011597\n",
      "Iter: 30 \tLoss: 0.21507425606250763\n",
      "Iter: 40 \tLoss: 0.20789852738380432\n",
      "Iter: 50 \tLoss: 0.270148366689682\n",
      "Iter: 60 \tLoss: 0.23262175917625427\n",
      "Iter: 70 \tLoss: 0.2213343232870102\n",
      "Iter: 80 \tLoss: 0.20362651348114014\n",
      "Iter: 90 \tLoss: 0.23929445445537567\n",
      "Iter: 100 \tLoss: 0.21796439588069916\n",
      "Iter: 110 \tLoss: 0.22216778993606567\n",
      "Mean Train Loss: 0.226482\n",
      "\n",
      "Val Loss: 0.316755 \tAccuracy: 0.8929787234042553\n",
      "Epoch: 11\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.23187854886054993\n",
      "Iter: 10 \tLoss: 0.2132018506526947\n",
      "Iter: 20 \tLoss: 0.1867118626832962\n",
      "Iter: 30 \tLoss: 0.20929808914661407\n",
      "Iter: 40 \tLoss: 0.22750863432884216\n",
      "Iter: 50 \tLoss: 0.21510367095470428\n",
      "Iter: 60 \tLoss: 0.22617919743061066\n",
      "Iter: 70 \tLoss: 0.2314617931842804\n",
      "Iter: 80 \tLoss: 0.24455341696739197\n",
      "Iter: 90 \tLoss: 0.17777611315250397\n",
      "Iter: 100 \tLoss: 0.23520393669605255\n",
      "Iter: 110 \tLoss: 0.20522482693195343\n",
      "Mean Train Loss: 0.217398\n",
      "\n",
      "Epoch: 12\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.2189921885728836\n",
      "Iter: 10 \tLoss: 0.17045770585536957\n",
      "Iter: 20 \tLoss: 0.21245993673801422\n",
      "Iter: 30 \tLoss: 0.1962156444787979\n",
      "Iter: 40 \tLoss: 0.2019091099500656\n",
      "Iter: 50 \tLoss: 0.20960377156734467\n",
      "Iter: 60 \tLoss: 0.19157005846500397\n",
      "Iter: 70 \tLoss: 0.24412092566490173\n",
      "Iter: 80 \tLoss: 0.2094094604253769\n",
      "Iter: 90 \tLoss: 0.20841144025325775\n",
      "Iter: 100 \tLoss: 0.19014091789722443\n",
      "Iter: 110 \tLoss: 0.20767921209335327\n",
      "Mean Train Loss: 0.210322\n",
      "\n",
      "Val Loss: 0.306292 \tAccuracy: 0.8963829787234042\n",
      "Epoch: 13\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.20391210913658142\n",
      "Iter: 10 \tLoss: 0.17188185453414917\n",
      "Iter: 20 \tLoss: 0.17409329116344452\n",
      "Iter: 30 \tLoss: 0.21464237570762634\n",
      "Iter: 40 \tLoss: 0.19790953397750854\n",
      "Iter: 50 \tLoss: 0.21079711616039276\n",
      "Iter: 60 \tLoss: 0.21943630278110504\n",
      "Iter: 70 \tLoss: 0.15194563567638397\n",
      "Iter: 80 \tLoss: 0.19380968809127808\n",
      "Iter: 90 \tLoss: 0.22795839607715607\n",
      "Iter: 100 \tLoss: 0.23038804531097412\n",
      "Iter: 110 \tLoss: 0.21341297030448914\n",
      "Mean Train Loss: 0.204125\n",
      "\n",
      "Epoch: 14\n",
      "Current Learning Rate: 0.1\n",
      "Iter: 0 \tLoss: 0.2266066074371338\n",
      "Iter: 10 \tLoss: 0.19717951118946075\n",
      "Iter: 20 \tLoss: 0.20248784124851227\n",
      "Iter: 30 \tLoss: 0.243024542927742\n",
      "Iter: 40 \tLoss: 0.15989014506340027\n",
      "Iter: 50 \tLoss: 0.18620672821998596\n",
      "Iter: 60 \tLoss: 0.20748648047447205\n",
      "Iter: 70 \tLoss: 0.19797557592391968\n",
      "Iter: 80 \tLoss: 0.1927204132080078\n",
      "Iter: 90 \tLoss: 0.2050454467535019\n",
      "Iter: 100 \tLoss: 0.18261981010437012\n",
      "Iter: 110 \tLoss: 0.24164728820323944\n",
      "Mean Train Loss: 0.196829\n",
      "\n",
      "Val Loss: 0.319133 \tAccuracy: 0.8953723404255319\n",
      "Epoch: 15\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.16094817221164703\n",
      "Iter: 10 \tLoss: 0.19585122168064117\n",
      "Iter: 20 \tLoss: 0.1806427389383316\n",
      "Iter: 30 \tLoss: 0.16664281487464905\n",
      "Iter: 40 \tLoss: 0.17659100890159607\n",
      "Iter: 50 \tLoss: 0.1579323559999466\n",
      "Iter: 60 \tLoss: 0.18385231494903564\n",
      "Iter: 70 \tLoss: 0.17124275863170624\n",
      "Iter: 80 \tLoss: 0.15255530178546906\n",
      "Iter: 90 \tLoss: 0.15850691497325897\n",
      "Iter: 100 \tLoss: 0.1471860706806183\n",
      "Iter: 110 \tLoss: 0.17856496572494507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Loss: 0.172620\n",
      "\n",
      "Epoch: 16\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.15164650976657867\n",
      "Iter: 10 \tLoss: 0.16147348284721375\n",
      "Iter: 20 \tLoss: 0.17757946252822876\n",
      "Iter: 30 \tLoss: 0.1483660787343979\n",
      "Iter: 40 \tLoss: 0.18232876062393188\n",
      "Iter: 50 \tLoss: 0.18739904463291168\n",
      "Iter: 60 \tLoss: 0.14118686318397522\n",
      "Iter: 70 \tLoss: 0.14825505018234253\n",
      "Iter: 80 \tLoss: 0.17571276426315308\n",
      "Iter: 90 \tLoss: 0.16858452558517456\n",
      "Iter: 100 \tLoss: 0.14754618704319\n",
      "Iter: 110 \tLoss: 0.16547055542469025\n",
      "Mean Train Loss: 0.166541\n",
      "\n",
      "Val Loss: 0.305364 \tAccuracy: 0.9012234042553191\n",
      "Epoch: 17\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.15442335605621338\n",
      "Iter: 10 \tLoss: 0.17026671767234802\n",
      "Iter: 20 \tLoss: 0.15187062323093414\n",
      "Iter: 30 \tLoss: 0.14468683302402496\n",
      "Iter: 40 \tLoss: 0.17007185518741608\n",
      "Iter: 50 \tLoss: 0.13838733732700348\n",
      "Iter: 60 \tLoss: 0.1547776311635971\n",
      "Iter: 70 \tLoss: 0.1599927544593811\n",
      "Iter: 80 \tLoss: 0.13198819756507874\n",
      "Iter: 90 \tLoss: 0.1556570827960968\n",
      "Iter: 100 \tLoss: 0.15311746299266815\n",
      "Iter: 110 \tLoss: 0.15399229526519775\n",
      "Mean Train Loss: 0.161877\n",
      "\n",
      "Epoch: 18\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.1820608675479889\n",
      "Iter: 10 \tLoss: 0.15340650081634521\n",
      "Iter: 20 \tLoss: 0.14171917736530304\n",
      "Iter: 30 \tLoss: 0.1614757925271988\n",
      "Iter: 40 \tLoss: 0.16635236144065857\n",
      "Iter: 50 \tLoss: 0.12988698482513428\n",
      "Iter: 60 \tLoss: 0.1570110321044922\n",
      "Iter: 70 \tLoss: 0.1842535138130188\n",
      "Iter: 80 \tLoss: 0.1940065175294876\n",
      "Iter: 90 \tLoss: 0.19908852875232697\n",
      "Iter: 100 \tLoss: 0.17886337637901306\n",
      "Iter: 110 \tLoss: 0.16024160385131836\n",
      "Mean Train Loss: 0.161100\n",
      "\n",
      "Val Loss: 0.309669 \tAccuracy: 0.9023936170212766\n",
      "Epoch: 19\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.1727599948644638\n",
      "Iter: 10 \tLoss: 0.1583106517791748\n",
      "Iter: 20 \tLoss: 0.1676909625530243\n",
      "Iter: 30 \tLoss: 0.15474161505699158\n",
      "Iter: 40 \tLoss: 0.17278756201267242\n",
      "Iter: 50 \tLoss: 0.16426140069961548\n",
      "Iter: 60 \tLoss: 0.1456572711467743\n",
      "Iter: 70 \tLoss: 0.18176203966140747\n",
      "Iter: 80 \tLoss: 0.16661910712718964\n",
      "Iter: 90 \tLoss: 0.17573916912078857\n",
      "Iter: 100 \tLoss: 0.18151675164699554\n",
      "Iter: 110 \tLoss: 0.1545649915933609\n",
      "Mean Train Loss: 0.157876\n",
      "\n",
      "Epoch: 20\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.1556805521249771\n",
      "Iter: 10 \tLoss: 0.1728878766298294\n",
      "Iter: 20 \tLoss: 0.1637800931930542\n",
      "Iter: 30 \tLoss: 0.1467929184436798\n",
      "Iter: 40 \tLoss: 0.16869176924228668\n",
      "Iter: 50 \tLoss: 0.1503937989473343\n",
      "Iter: 60 \tLoss: 0.15141025185585022\n",
      "Iter: 70 \tLoss: 0.12267133593559265\n",
      "Iter: 80 \tLoss: 0.1538059562444687\n",
      "Iter: 90 \tLoss: 0.14723360538482666\n",
      "Iter: 100 \tLoss: 0.16651207208633423\n",
      "Iter: 110 \tLoss: 0.16745592653751373\n",
      "Mean Train Loss: 0.157275\n",
      "\n",
      "Val Loss: 0.312845 \tAccuracy: 0.9020212765957447\n",
      "Epoch: 21\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.131508007645607\n",
      "Iter: 10 \tLoss: 0.18739168345928192\n",
      "Iter: 20 \tLoss: 0.17142322659492493\n",
      "Iter: 30 \tLoss: 0.1404038369655609\n",
      "Iter: 40 \tLoss: 0.1418599933385849\n",
      "Iter: 50 \tLoss: 0.14720238745212555\n",
      "Iter: 60 \tLoss: 0.1481967568397522\n",
      "Iter: 70 \tLoss: 0.13178953528404236\n",
      "Iter: 80 \tLoss: 0.15871991217136383\n",
      "Iter: 90 \tLoss: 0.17542116343975067\n",
      "Iter: 100 \tLoss: 0.1512056589126587\n",
      "Iter: 110 \tLoss: 0.13672120869159698\n",
      "Mean Train Loss: 0.154394\n",
      "\n",
      "Epoch: 22\n",
      "Current Learning Rate: 0.010000000000000002\n",
      "Iter: 0 \tLoss: 0.16077981889247894\n",
      "Iter: 10 \tLoss: 0.15370549261569977\n",
      "Iter: 20 \tLoss: 0.1484806388616562\n",
      "Iter: 30 \tLoss: 0.15069951117038727\n",
      "Iter: 40 \tLoss: 0.14419688284397125\n",
      "Iter: 50 \tLoss: 0.1560191661119461\n",
      "Iter: 60 \tLoss: 0.14988593757152557\n",
      "Iter: 70 \tLoss: 0.16218459606170654\n",
      "Iter: 80 \tLoss: 0.16782422363758087\n",
      "Iter: 90 \tLoss: 0.1443503499031067\n",
      "Iter: 100 \tLoss: 0.14346539974212646\n",
      "Iter: 110 \tLoss: 0.14726513624191284\n",
      "Mean Train Loss: 0.153684\n",
      "\n",
      "Val Loss: 0.316071 \tAccuracy: 0.901595744680851\n",
      "Epoch: 23\n",
      "Current Learning Rate: 0.0010000000000000002\n",
      "Iter: 0 \tLoss: 0.14421230554580688\n",
      "Iter: 10 \tLoss: 0.12932075560092926\n",
      "Iter: 20 \tLoss: 0.13984227180480957\n",
      "Iter: 30 \tLoss: 0.1465832144021988\n",
      "Iter: 40 \tLoss: 0.14979630708694458\n",
      "Iter: 50 \tLoss: 0.1704709231853485\n",
      "Iter: 60 \tLoss: 0.14400595426559448\n",
      "Iter: 70 \tLoss: 0.15117822587490082\n",
      "Iter: 80 \tLoss: 0.1397763192653656\n",
      "Iter: 90 \tLoss: 0.15716271102428436\n",
      "Iter: 100 \tLoss: 0.13275869190692902\n",
      "Iter: 110 \tLoss: 0.15818825364112854\n",
      "Mean Train Loss: 0.150723\n",
      "\n",
      "Epoch: 24\n",
      "Current Learning Rate: 0.0010000000000000002\n",
      "Iter: 0 \tLoss: 0.14198139309883118\n",
      "Iter: 10 \tLoss: 0.15467076003551483\n",
      "Iter: 20 \tLoss: 0.13672469556331635\n",
      "Iter: 30 \tLoss: 0.15910138189792633\n",
      "Iter: 40 \tLoss: 0.15166066586971283\n",
      "Iter: 50 \tLoss: 0.16065771877765656\n",
      "Iter: 60 \tLoss: 0.14190198481082916\n",
      "Iter: 70 \tLoss: 0.17665448784828186\n",
      "Iter: 80 \tLoss: 0.1415739357471466\n",
      "Iter: 90 \tLoss: 0.1400652974843979\n",
      "Iter: 100 \tLoss: 0.13391418755054474\n",
      "Iter: 110 \tLoss: 0.16229787468910217\n",
      "Mean Train Loss: 0.149730\n",
      "\n",
      "Val Loss: 0.316173 \tAccuracy: 0.9018085106382979\n",
      "Epoch: 25\n",
      "Current Learning Rate: 0.0010000000000000002\n",
      "Iter: 0 \tLoss: 0.13056153059005737\n",
      "Iter: 10 \tLoss: 0.1403474658727646\n",
      "Iter: 20 \tLoss: 0.14964120090007782\n",
      "Iter: 30 \tLoss: 0.1440039426088333\n",
      "Iter: 40 \tLoss: 0.12875618040561676\n",
      "Iter: 50 \tLoss: 0.13459394872188568\n",
      "Iter: 60 \tLoss: 0.1642279028892517\n",
      "Iter: 70 \tLoss: 0.15290795266628265\n",
      "Iter: 80 \tLoss: 0.1516856998205185\n",
      "Iter: 90 \tLoss: 0.14236755669116974\n",
      "Iter: 100 \tLoss: 0.1555267572402954\n",
      "Iter: 110 \tLoss: 0.16140151023864746\n",
      "Mean Train Loss: 0.149476\n",
      "\n",
      "Epoch: 26\n",
      "Current Learning Rate: 0.0010000000000000002\n",
      "Iter: 0 \tLoss: 0.1273190975189209\n",
      "Iter: 10 \tLoss: 0.1537250131368637\n",
      "Iter: 20 \tLoss: 0.16602414846420288\n",
      "Iter: 30 \tLoss: 0.14498621225357056\n",
      "Iter: 40 \tLoss: 0.15957629680633545\n",
      "Iter: 50 \tLoss: 0.14033393561840057\n",
      "Iter: 60 \tLoss: 0.15871328115463257\n",
      "Iter: 70 \tLoss: 0.14393794536590576\n",
      "Iter: 80 \tLoss: 0.14287060499191284\n",
      "Iter: 90 \tLoss: 0.174424409866333\n",
      "Iter: 100 \tLoss: 0.12555836141109467\n",
      "Iter: 110 \tLoss: 0.1474444717168808\n",
      "Mean Train Loss: 0.149943\n",
      "\n",
      "Val Loss: 0.316667 \tAccuracy: 0.9019148936170213\n",
      "Epoch: 27\n",
      "Current Learning Rate: 0.0010000000000000002\n",
      "Iter: 0 \tLoss: 0.14771166443824768\n",
      "Iter: 10 \tLoss: 0.15803182125091553\n",
      "Iter: 20 \tLoss: 0.13822324573993683\n",
      "Iter: 30 \tLoss: 0.14145804941654205\n",
      "Iter: 40 \tLoss: 0.15713058412075043\n",
      "Iter: 50 \tLoss: 0.15898697078227997\n",
      "Iter: 60 \tLoss: 0.15200236439704895\n",
      "Iter: 70 \tLoss: 0.1432846635580063\n",
      "Iter: 80 \tLoss: 0.1737968474626541\n",
      "Iter: 90 \tLoss: 0.1511710286140442\n",
      "Iter: 100 \tLoss: 0.1369437277317047\n",
      "Iter: 110 \tLoss: 0.14590409398078918\n",
      "Mean Train Loss: 0.149213\n",
      "\n",
      "Epoch: 28\n",
      "Current Learning Rate: 0.0010000000000000002\n",
      "Iter: 0 \tLoss: 0.1688157320022583\n",
      "Iter: 10 \tLoss: 0.14062222838401794\n",
      "Iter: 20 \tLoss: 0.16666075587272644\n",
      "Iter: 30 \tLoss: 0.144375741481781\n",
      "Iter: 40 \tLoss: 0.14802587032318115\n",
      "Iter: 50 \tLoss: 0.17925791442394257\n",
      "Iter: 60 \tLoss: 0.16256292164325714\n",
      "Iter: 70 \tLoss: 0.18669676780700684\n",
      "Iter: 80 \tLoss: 0.1740681529045105\n",
      "Iter: 90 \tLoss: 0.1565118283033371\n",
      "Iter: 100 \tLoss: 0.13384538888931274\n",
      "Iter: 110 \tLoss: 0.13213399052619934\n",
      "Mean Train Loss: 0.149686\n",
      "\n",
      "Val Loss: 0.316408 \tAccuracy: 0.9026063829787234\n",
      "Epoch: 29\n",
      "Current Learning Rate: 0.0010000000000000002\n",
      "Iter: 0 \tLoss: 0.1539987027645111\n",
      "Iter: 10 \tLoss: 0.1457078754901886\n",
      "Iter: 20 \tLoss: 0.15401753783226013\n",
      "Iter: 30 \tLoss: 0.15041141211986542\n",
      "Iter: 40 \tLoss: 0.15207327902317047\n",
      "Iter: 50 \tLoss: 0.13920831680297852\n",
      "Iter: 60 \tLoss: 0.13366606831550598\n",
      "Iter: 70 \tLoss: 0.16135388612747192\n",
      "Iter: 80 \tLoss: 0.1500990241765976\n",
      "Iter: 90 \tLoss: 0.1701628416776657\n",
      "Iter: 100 \tLoss: 0.1562805324792862\n",
      "Iter: 110 \tLoss: 0.1708602011203766\n",
      "Mean Train Loss: 0.148779\n",
      "\n",
      "Val Loss: 0.316923 \tAccuracy: 0.9021808510638298\n",
      "CPU times: total: 23min 18s\n",
      "Wall time: 23min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.316923168144728"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = CNN(47)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "n_epoch = 30\n",
    "val_fre = 2\n",
    "\n",
    "train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre)\n",
    "validate(model, val_loader, loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c326d2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3169, Val Accuracy: 0.9022, Val F1-Score: 0.9016\n",
      "\n",
      "True: F, Predicted: f, Error rate: 138\n",
      "True: L, Predicted: 1, Error rate: 137\n",
      "True: O, Predicted: 0, Error rate: 119\n",
      "True: f, Predicted: F, Error rate: 94\n",
      "True: 0, Predicted: O, Error rate: 89\n",
      "True: q, Predicted: 9, Error rate: 89\n",
      "True: I, Predicted: 1, Error rate: 87\n",
      "True: L, Predicted: I, Error rate: 59\n",
      "True: 1, Predicted: L, Error rate: 53\n",
      "True: 1, Predicted: I, Error rate: 50\n",
      "True: g, Predicted: q, Error rate: 41\n",
      "True: g, Predicted: 9, Error rate: 37\n",
      "True: q, Predicted: g, Error rate: 35\n",
      "True: 9, Predicted: q, Error rate: 32\n",
      "True: I, Predicted: L, Error rate: 30\n",
      "True: 2, Predicted: Z, Error rate: 29\n",
      "True: 5, Predicted: S, Error rate: 27\n",
      "True: 9, Predicted: g, Error rate: 27\n",
      "True: Z, Predicted: 2, Error rate: 23\n",
      "True: t, Predicted: T, Error rate: 20\n",
      "True: T, Predicted: t, Error rate: 15\n",
      "True: b, Predicted: 6, Error rate: 15\n",
      "True: 6, Predicted: b, Error rate: 14\n",
      "True: D, Predicted: 0, Error rate: 14\n",
      "True: S, Predicted: 5, Error rate: 14\n",
      "True: V, Predicted: U, Error rate: 14\n",
      "True: n, Predicted: N, Error rate: 13\n",
      "True: q, Predicted: Q, Error rate: 13\n",
      "True: f, Predicted: t, Error rate: 12\n",
      "True: g, Predicted: a, Error rate: 12\n",
      "True: U, Predicted: V, Error rate: 11\n"
     ]
    }
   ],
   "source": [
    "# посмотрим ещё раз на метрики и самые частые ошибки в валидацинном наборе данных:\n",
    "\n",
    "def get_most_common_errors(cm, label_mapping, threshold=10):\n",
    "    errors = np.where((cm - np.diag(np.diag(cm))) > threshold)\n",
    "    error_list = []\n",
    "    for true_label, pred_label in zip(errors[0], errors[1]):\n",
    "        true_symbol = label_mapping[true_label]\n",
    "        pred_symbol = label_mapping[pred_label]\n",
    "        error_count = cm[true_label, pred_label]\n",
    "        error_list.append((true_symbol, pred_symbol, error_count))\n",
    "        \n",
    "    sorted_errors = sorted(error_list, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return sorted_errors\n",
    "\n",
    "def evaluate(model, data_loader, loss_f):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_f(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy, f1, cm\n",
    "\n",
    "val_loss, val_accuracy, val_f1, val_cm = evaluate(model, val_loader, loss_f)\n",
    "print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1-Score: {val_f1:.4f}\\n\")\n",
    "\n",
    "sorted_errors = get_most_common_errors(val_cm, mapping)\n",
    "for true_symbol, pred_symbol, error_count in sorted_errors:\n",
    "    print(f\"True: {true_symbol}, Predicted: {pred_symbol}, Error rate: {error_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ebe0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'myapp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa30f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
